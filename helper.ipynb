{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3edf9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys,re,json\n",
    "from pathlib import Path\n",
    "import fitz,pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_core.documents import Document\n",
    "from typing import Optional,Dict,List\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os,sys\n",
    "from pathlib import Path\n",
    "# Base_dir = Path(__file__).resolve().parent.parent\n",
    "# sys.path.append(str(Base_dir))\n",
    "# from Bot.Data_preparation import extract_text_from_pdf,merge_number_line,detect_heading,detect_tables_text\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_classic.memory import ConversationBufferWindowMemory\n",
    "from langchain_google_genai import GoogleGenerativeAI,ChatGoogleGenerativeAI,GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_classic.retrievers import EnsembleRetriever,ContextualCompressionRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.documents import Document\n",
    "from langchain_classic.retrievers.document_compressors import LLMChainExtractor,LLMChainFilter,DocumentCompressorPipeline\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain_community.document_compressors import FlashrankRerank\n",
    "from langchain_core.documents import Document as LCDocument\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "import os,sys\n",
    "from pathlib import Path \n",
    "# Base_dir = Path(__file__).resolve().parent.parent\n",
    "# sys.path.append(str(Base_dir))\n",
    "from Bots.Data_preparation import attach_images_to_paragraphs,extract_text,detect_images,pdf_paths\n",
    "from langchain_core.documents import Document\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_classic.retrievers import ContextualCompressionRetriever,EnsembleRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_classic.retrievers.document_compressors import LLMChainExtractor,LLMChainFilter,DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain_community.document_compressors import FlashrankRerank\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from typing import Sequence,Annotated,List,Optional,Dict,Literal\n",
    "from langchain_classic import hub\n",
    "from langgraph.graph import MessagesState,StateGraph,END,START\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from pydantic import BaseModel,Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_classic.agents import Tool,create_react_agent,create_self_ask_with_search_agent\n",
    "from langchain_community.tools import TavilySearchResults,TavilyAnswer\n",
    "load_dotenv()\n",
    "from langchain_classic.prompts import ChatPromptTemplate,PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,PydanticOutputParser\n",
    "\n",
    "doc_path = Path.cwd() / \"Data\"\n",
    "pdf_paths = doc_path / \"ISO-7001-2023.pdf\"\n",
    "\n",
    "#Detect Images:\n",
    "def detect_images(pdf_path, output_dir=\"images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        pix = page.get_pixmap()\n",
    "        image_name = f\"page_{page_num+1}.png\"\n",
    "        image_path = os.path.join(output_dir, image_name)\n",
    "        pix.save(image_path)\n",
    "\n",
    "        images.append({\n",
    "            \"page_num\": page_num + 1,\n",
    "            \"image_path\": image_path\n",
    "        })\n",
    "        # blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        # img_index = 0\n",
    "        # for block in blocks:\n",
    "        #     if block[\"type\"] == 1 and \"xref\" in block:  # image block\n",
    "        #         bbox = block[\"bbox\"]\n",
    "        #         pix = page.get_pixmap(clip = fitz.Rect(bbox))\n",
    "        #         if pix.n > 4:\n",
    "        #             pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "\n",
    "        #         image_name = f\"page_{page_num+1}_Img_{img_index}.png\"\n",
    "        #         image_path = os.path.join(output_dir, image_name)\n",
    "        #         pix.save(image_path)\n",
    "\n",
    "        #         images.append({\n",
    "        #             \"page_num\": page_num + 1,\n",
    "        #             \"bbox\": bbox,\n",
    "        #             \"image_path\": image_path\n",
    "        #         })\n",
    "\n",
    "        #         img_index += 1\n",
    "                #   pix = None\n",
    "    doc.close()\n",
    "    return images\n",
    "detect_images(pdf_paths)\n",
    "\n",
    "\n",
    "#Detect Headings:\n",
    "def detect_heading(line:str,font_info:Optional[Dict]=None)->str:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return None\n",
    "    \n",
    "    match = re.match(r'^(\\d+(?:\\.\\d+){0,3})\\s+(.+)$', line)\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "        dot_count = prefix.count(\".\")\n",
    "\n",
    "        if dot_count ==0:\n",
    "           classification = \"heading\"\n",
    "        elif dot_count==1:\n",
    "            classification = \"sub_heading\"\n",
    "        elif dot_count ==2:\n",
    "            classification = \"sub_sub_heading\"\n",
    "        else:\n",
    "            classification = None\n",
    "\n",
    "        if font_info:\n",
    "            font_name = font_info.get(\"font\",\"\").strip.lower()\n",
    "            font_size = font_info.get(\"size\",0)\n",
    "            if \"bold\" or \"italic\" in font_info or font_size>=12:\n",
    "                return classification\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        return classification\n",
    "        \n",
    "    #Non numbered but bold\n",
    "    if font_info:\n",
    "        font_name = font_info.get(\"font\", \"\").lower()\n",
    "        font_size = font_info.get(\"size\", 0)\n",
    "        if \"bold\" in font_name and font_size >= 10:\n",
    "            return \"sub_heading\"\n",
    "        \n",
    "    #Number headings\n",
    "    only_number = re.match(r'^(\\d+(?:\\.\\d+){0,3})$', line)\n",
    "    if only_number:\n",
    "        prefix = only_number.group(1)\n",
    "        dot_count = prefix.count(\".\")\n",
    "\n",
    "        if dot_count == 0:\n",
    "            return \"heading\"\n",
    "        elif dot_count == 1:\n",
    "            return \"sub_heading\"\n",
    "        \n",
    "    return None\n",
    "\n",
    "#Extraction of text:\n",
    "def extract_text(pdf_path):\n",
    "    doc =fitz.open(pdf_path)\n",
    "    structured_data = []\n",
    "    current_section = None\n",
    "    current_sub_section = None\n",
    "    current_sub_sub_section = None\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        page_dict = page.get_text(\"dict\")\n",
    "        page_lines = []\n",
    "        \n",
    "        for blocks in page_dict.get(\"blocks\",[]):\n",
    "            for lines in blocks.get(\"lines\",[]):\n",
    "                line_text = \"\\n\".join([span.get('text') for span in lines.get(\"spans\",[])])\n",
    "                # print(repr(line_text))\n",
    "                if not line_text:\n",
    "                    continue\n",
    "                \n",
    "                if (\n",
    "                        re.match(r\"^ISO\\s+\\d{4,5}:\\d{4}\\(E\\)$\", line_text)\n",
    "                        or re.search(r\"© ISO \\d{4} – All rights reserved\", line_text)\n",
    "                   \n",
    "                    ):\n",
    "                        continue\n",
    "                page_lines.append(line_text)     \n",
    "        # print(page_lines)\n",
    "\n",
    "        #Paragraph initiation\n",
    "        current_para = \"\"\n",
    "        for line in page_lines:\n",
    "            line = line.replace('\\ufeff', '').replace('\\x08', '').replace('\\xa0','').strip()\n",
    "            line = re.sub(r'\\s+', ' ', line).strip()\n",
    "            if not line:\n",
    "                if current_para:\n",
    "                    structured_data.append({\n",
    "                        \"Document_name\": pdf_path,\n",
    "                                \"page_num\": page_num + 1,\n",
    "                                \"heading\": current_section,\n",
    "                                \"sub_heading\": current_sub_section,\n",
    "                                \"sub_sub_heading\": current_sub_sub_section,\n",
    "                                \"paragraph\": current_para.strip()\n",
    "                    })\n",
    "\n",
    "                    current_para = \"\"\n",
    "                continue\n",
    "\n",
    "            #Detect heading\n",
    "            classification = detect_heading(line)\n",
    "            if classification in [\"heading\",\"sub_heading\",\"sub_sub_heading\"]:\n",
    "                if current_para:\n",
    "                    structured_data.append({\n",
    "                        \"Document_name\": pdf_path,\n",
    "                                \"page_num\": page_num + 1,\n",
    "                                \"heading\": current_section,\n",
    "                                \"sub_heading\": current_sub_section,\n",
    "                                \"sub_sub_heading\": current_sub_sub_section,\n",
    "                                \"paragraph\": current_para.strip()\n",
    "                    })\n",
    "\n",
    "                    current_para = \"\"\n",
    "\n",
    "            # Update trackers\n",
    "                if classification == \"heading\":\n",
    "                    current_section = line\n",
    "                    current_sub_section = None\n",
    "                    current_sub_sub_section = None\n",
    "                elif classification == \"sub_heading\":\n",
    "                    current_sub_section = line\n",
    "                    current_sub_sub_section = None\n",
    "                elif classification == \"sub_sub_heading\":\n",
    "                    current_sub_sub_section = line\n",
    "            \n",
    "\n",
    "            if re.match(r\"^([a-z]\\)|\\d+\\.|\\-|•)\\s+.+\", line):\n",
    "                if current_para:\n",
    "                    current_para += \" \" + line\n",
    "                else:\n",
    "                    current_para = line\n",
    "            else:\n",
    "                if current_para:\n",
    "                    current_para += \" \" + line\n",
    "                else:\n",
    "                    current_para = line\n",
    "\n",
    "            # Finalize last paragraph on page\n",
    "        if current_para:\n",
    "            structured_data.append({\n",
    "                \"Document_name\":pdf_path,\n",
    "                \"page_num\": page_num + 1,\n",
    "                \"heading\": current_section,\n",
    "                \"sub_heading\": current_sub_section,\n",
    "                \"sub_sub_heading\": current_sub_sub_section,\n",
    "                \"paragraph\": current_para.strip()\n",
    "            })\n",
    "    doc.close()\n",
    "    return {\"Paragraphs\":structured_data}\n",
    "\n",
    "def attach_images_to_paragraphs(structured_data, images):\n",
    "    \"\"\"\n",
    "    Attach images to all paragraphs under the same heading context\n",
    "    until the next heading appears.\n",
    "    \"\"\"\n",
    "    # Group paragraphs by page\n",
    "    page_paragraphs = {}\n",
    "    for idx, para in enumerate(structured_data):\n",
    "        page_paragraphs.setdefault(para[\"page_num\"], []).append(idx)\n",
    "\n",
    "    for img in images:\n",
    "        pg_num = img[\"page_num\"]\n",
    "        if pg_num not in page_paragraphs:\n",
    "            continue\n",
    "\n",
    "        # Attach image to all paragraphs on the page (context until next heading)\n",
    "        for idx in page_paragraphs[pg_num]:\n",
    "            if \"images\" not in structured_data[idx]:\n",
    "                structured_data[idx][\"images\"] = []\n",
    "            structured_data[idx][\"images\"].append(img[\"image_path\"])\n",
    "\n",
    "    return structured_data\n",
    "\n",
    "pdf_path = pdf_paths\n",
    "output_dir = \"images\"\n",
    "\n",
    "# 1️⃣ Extract text\n",
    "text_data = extract_text(pdf_path)\n",
    "paragraphs = text_data[\"Paragraphs\"]\n",
    "\n",
    "# 2️⃣ Extract images\n",
    "images = detect_images(pdf_path, output_dir=output_dir)\n",
    "\n",
    "# 3️⃣ Attach images contextually\n",
    "final_data = attach_images_to_paragraphs(paragraphs, images)\n",
    "\n",
    "# 4️⃣ Check sample output\n",
    "# for item in final_data:\n",
    "#     print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c2dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "INFO:langchain_astradb.vectorstores:vector store default init, collection 'Bot_collection_HIL'\n",
      "INFO:root:Detecting API environment 'prod' from supplied endpoint\n",
      "INFO:astrapy.data.database:createCollection('Bot_collection_HIL')\n",
      "INFO:httpx:HTTP Request: POST https://da560a44-8a47-47c1-9200-eb2f9e31c431-us-east1.apps.astra.datastax.com/api/json/v1/default_keyspace \"HTTP/1.1 200 OK\"\n",
      "INFO:astrapy.data.database:finished createCollection('Bot_collection_HIL')\n"
     ]
    }
   ],
   "source": [
    "ASTRA_DB_API_ENDPOINT=os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "ASTRA_DB_APPLICATION_TOKEN=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "AstraDB_Keyspace = 'default_keyspace'\n",
    "\n",
    "GOOGLE_API_KEY  = os.getenv(\"GOOGLE_API_KEY\")\n",
    "Tavily_API_Key = os.getenv(\"TAVILY_API_KEY\") or \"tavily_xxx\"\n",
    "Langchain_API_Key = os.getenv(\"LANGCHAIN_API_KEY\") or \"lsmith_xxx\"\n",
    "GROQ_API_KEY= os.getenv(\"GROQ_API_KEY\") or \"groq_xxx\"\n",
    "# Set environment variables\n",
    "os.environ[\"TAVILY_API_KEY\"] = Tavily_API_Key\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = Langchain_API_Key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\",encode_kwargs={\"normalize_embeddings\": True})\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    api_key=GROQ_API_KEY,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "def sanitize_metadata(metadata):\n",
    "    clean_meta = {}\n",
    "\n",
    "    for k, v in metadata.items():\n",
    "        key = k.replace(\" \", \"_\").lower()   \n",
    "        if isinstance(v, Path):\n",
    "            clean_meta[key] = str(v)\n",
    "        elif isinstance(v, list):\n",
    "            clean_meta[key] = [\n",
    "                str(i) if isinstance(i, Path) else i\n",
    "                for i in v\n",
    "            ]\n",
    "        elif isinstance(v, (str, int, float, bool)) or v is None:\n",
    "            clean_meta[key] = v\n",
    "        else:\n",
    "            clean_meta[key] = str(v)\n",
    "\n",
    "    return clean_meta\n",
    "\n",
    "# 1. Extract text\n",
    "doc = extract_text(pdf_paths)\n",
    "structured_data = doc[\"Paragraphs\"]\n",
    "\n",
    "# 2. Extract images\n",
    "images = detect_images(pdf_paths)\n",
    "\n",
    "# 3. Attach images\n",
    "structured_data = attach_images_to_paragraphs(structured_data, images)\n",
    "\n",
    "\n",
    "def chunk_text(structured_data,chunk_size=550,chunk_overlap=300):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap,separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"])\n",
    "    text_chunks = []\n",
    "\n",
    "    for record in structured_data:\n",
    "        metadata = {\n",
    "            \"Document_name\":record.get(\"Document_name\"),\n",
    "            \"Page num\":record.get(\"page_num\"),\n",
    "            \"Heading\":record.get(\"heading\"),\n",
    "            \"Sub Heading\":record.get(\"sub_heading\"),\n",
    "            \"Sub_sub_heading\":record.get(\"sub_sub_heading\"),\n",
    "            \"snippet\":record.get(\"images\"),\n",
    "        }\n",
    "\n",
    "        for chunk in text_splitter.split_text(record.get(\"paragraph\")):\n",
    "            text_chunks.append({\"text\":chunk,\"metadata\":metadata})\n",
    "    return text_chunks\n",
    "\n",
    "chunks = chunk_text(structured_data)\n",
    "all_chunks=[]\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # print(i, type(chunk.get(\"metadata\")), chunk.get(\"metadata\"))\n",
    "    # if not isinstance(chunk.get(\"metadata\"), dict):\n",
    "    #     print(\"INVALID METADATA FOUND AT INDEX:\", i)\n",
    "    #     break\n",
    "    clean_metadata = sanitize_metadata(chunk['metadata'])\n",
    "    all_chunks.append(Document(page_content=chunk['text'],metadata=clean_metadata))\n",
    "\n",
    "#2.Embedding\n",
    "sample_query = \"Definition post-market surveillance\"\n",
    "sample_embed = embeddings.embed_query(sample_query)\n",
    "# print(f\"First five dimensions of embeddings were:{sample_embed[:5]}\")\n",
    "\n",
    "#3. Vector store\n",
    "vector_store = AstraDBVectorStore(\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"Bot_collection_HIL\",\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token = ASTRA_DB_APPLICATION_TOKEN,\n",
    "    namespace=AstraDB_Keyspace\n",
    ")\n",
    "\n",
    "#4. Injestion:\n",
    "# vector_store.add_documents(all_chunks)\n",
    "# print(f\"Total chunks created were {len(all_chunks)}\")\n",
    "# print(f\" All documents ingested successfully {len(all_chunks)}\")\n",
    "\n",
    "# #5. Retriever\n",
    "reorder = LongContextReorder()\n",
    "FlashrankRerank.model_rebuild()\n",
    "reranker = FlashrankRerank(model=\"ms-marco-MiniLM-L-12-v2\", top_n=10)\n",
    "# compressor = LLMChainExtractor.from_llm(llm)\n",
    "# filter = LLMChainFilter.from_llm(llm)\n",
    "keyword_retriever = BM25Retriever.from_documents(all_chunks)\n",
    "keyword_retriever.k=5\n",
    "vector_retriever = vector_store.as_retriever(search_type=\"similarity\",kwargs={\"k\":5})\n",
    "hybrid_retriever= EnsembleRetriever(retrievers=[keyword_retriever,vector_retriever],weights=[0.5,0.5])\n",
    "pipeline = DocumentCompressorPipeline(transformers=[reranker])\n",
    "retriever = ContextualCompressionRetriever(base_compressor=pipeline,base_retriever=hybrid_retriever)\n",
    "\n",
    "# if __name__==\"__main__\":\n",
    "#     query = \"What is Negation?\"\n",
    "#     answer =retriever.invoke(query)\n",
    "#     print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7e1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memory:\n",
    "memory = ConversationBufferWindowMemory(k=17, memory_key=\"Chat_History\",return_messages=True)\n",
    "def format_chat_history():\n",
    "    \"\"\"Read memory and format as string for prompt\"\"\"\n",
    "    chat_history_str = \"\"\n",
    "    for message in memory.chat_memory.messages:\n",
    "        if isinstance(message,HumanMessage):\n",
    "            chat_history_str +=f\"Human message:{message.content}\\n\"\n",
    "        elif isinstance(message,AIMessage):\n",
    "            chat_history_str +=f\"Human message:{message.content}\\n\"\n",
    "    return chat_history_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc2ace65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:astrapy.data.cursors.cursor:cursor fetching a page: (empty page state) from Bot_collection_HIL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____Retriever____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://da560a44-8a47-47c1-9200-eb2f9e31c431-us-east1.apps.astra.datastax.com/api/json/v1/default_keyspace/Bot_collection_HIL \"HTTP/1.1 200 OK\"\n",
      "INFO:astrapy.data.cursors.cursor:cursor finished fetching a page: (empty page state) from Bot_collection_HIL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____Grader____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question will be transformed by rewriting the query in a way that web search can able to understand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____Generate____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like the web results provided are not relevant to the question about Tavily search formulation. The content appears to be a jumbled collection of letters and symbols, possibly a fragment of an HTTP error message.\n",
      "\n",
      "To better answer your question, I'll try to provide a general response. Tavily search formulation is not a widely recognized term, and without more context, it's challenging to provide specific applications, benefits, or advantages. However, I can suggest some possible areas where search formulation might be utilized:\n",
      "\n",
      "1. **Information Retrieval**: Search formulation can be crucial in retrieving relevant information from large datasets or databases. A well-crafted search query can help users find the desired information efficiently.\n",
      "2. **Natural Language Processing (NLP)**: Search formulation can be applied to NLP tasks, such as text classification, sentiment analysis, or question-answering systems.\n",
      "3. **Web Search**: Search formulation can be used to improve web search results by optimizing search queries, using relevant keywords, and filtering out irrelevant information.\n",
      "\n",
      "If you could provide more context or clarify what Tavily search formulation refers to, I'll do my best to provide a more specific and accurate response.\n"
     ]
    }
   ],
   "source": [
    "#Corrective RAG--->Agentic AI\n",
    "\n",
    "def make_msgpack_safe(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: make_msgpack_safe(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_msgpack_safe(v) for v in obj]\n",
    "    elif isinstance(obj, np.generic):  # numpy.float32, int64, etc.\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, (float, int, str, bool)) or obj is None:\n",
    "        return obj\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "#Web Prompt:\n",
    "web_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert assistant.\n",
    "Use web search results to answer the user's question.\n",
    "Do NOT say 'I don't know'.\n",
    "You can also respond to general greetings like \"hi\", \"hello\", \"who are you\", etc. Ignore spelling mistakes.\n",
    "If spelling mistakes from user understand the intent what they were trying to ask. If people asking some tricky psycological question about your confidence, handle diplomatically.\n",
    "     \n",
    "     \"\"\"),\n",
    "    (\"human\", \"\"\"Conversation so far:\n",
    "{chat_history}\n",
    "\n",
    "Current Question:\n",
    "{question}\n",
    "\n",
    "Web Results:\n",
    "{context}\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "#1. Grader node\n",
    "class grade_docs(BaseModel):\n",
    "    binary_score: str=Field(\"Grade the retrieved documents with its relevance and say yes or no\")\n",
    "llm_with_structured_output = llm.with_structured_output(grade_docs)\n",
    "\n",
    "system = \"\"\"You are a relevance grader for Corrective RAG.\n",
    "\n",
    "Rules:\n",
    "- Compare the document and the user question.\n",
    "- If the document is relevant, output \"Yes\".\n",
    "- If the document is irrelevant, empty, or off-topic, output \"No\".\n",
    "- Output ONLY \"Yes\" or \"No\". \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"\"\"Conversation so far:\n",
    "{chat_history}\n",
    "\n",
    "Retrieved Document:\n",
    "{documents}\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "])\n",
    "grader = prompt | llm_with_structured_output\n",
    "# question = \"question\"\n",
    "# docs = retriever.invoke(question)\n",
    "# if not docs or len(docs)==0:\n",
    "#     result={\n",
    "#         \"binary_score\":\"No\",\n",
    "#         \"reason\": \"No relevant documents found\"\n",
    "#     }\n",
    "#     # print(result)\n",
    "# else:\n",
    "#     context = \"\\n\".join(d.page_content for d in docs[:3] if d.page_content)\n",
    "\n",
    "#     if not context.strip():\n",
    "#         result = { \"binary_score\":\"No\",\n",
    "#         \"reason\": \"Documents are not that releavant\"}\n",
    "\n",
    "#     else:\n",
    "#         grade_answer = grader.invoke({\"question\":question,\"documents\":docs[1].page_content})\n",
    "\n",
    "    # print(grade_answer)\n",
    "\n",
    "#2. Generate node\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an assistant for question-answering tasks.\n",
    "\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Conversation history is provided for context only.\n",
    "Do NOT use conversation history as a source of truth unless supported by retrieved context.\n",
    "\n",
    "You can also respond to general greetings like \"hi\", \"hello\", \"who are you\", etc. Ignore spelling mistakes.\n",
    "If spelling mistakes from user understand the intent what they were trying to ask. If people asking some tricky psycological question about your confidence, handle diplomatically.\n",
    "\n",
    "\"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "Retrieved Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "def format_documents(documents):\n",
    "    formatted = []\n",
    "\n",
    "    for i, d in enumerate(documents[:3], 1):\n",
    "        meta = d.get(\"metadata\", {})\n",
    "\n",
    "        formatted.append(\n",
    "            f\"\"\"[Document {i}]\n",
    "Source: {meta.get(\"document_name\", \"Unknown\")}\n",
    "Page: {meta.get(\"page_num\", \"N/A\")}\n",
    "Heading: {meta.get(\"heading\", \"N/A\")}\n",
    "Sub Heading: {meta.get(\"sub_heading\", \"N/A\")}\n",
    "Sub-sub Heading: {meta.get(\"sub_sub_heading\", \"N/A\")}\n",
    "Images: {meta.get(\"snippet\", \"N/A\")}\n",
    "\n",
    "Content:\n",
    "{d[\"page_content\"]}\n",
    "\"\"\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_documents(x['documents']),\n",
    "        \"question\": lambda x : x['question'],\n",
    "        \"chat_history\": lambda _: format_chat_history(), \n",
    "        \n",
    "    }\n",
    "    |rag_prompt\n",
    "    |llm\n",
    "    |output_parser\n",
    ")\n",
    "\n",
    "web_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_documents(x['documents']),\n",
    "        \"question\": lambda x: x['question'],\n",
    "        \"chat_history\": lambda _: format_chat_history(),\n",
    "    }\n",
    "    |web_prompt\n",
    "    |llm\n",
    "    |output_parser\n",
    ")\n",
    "# generate = rag_chain.invoke({\"question\":\"what is negation\",\"documents\":docs})\n",
    "\n",
    "\n",
    "#3.Rewrite Query\n",
    "system = \"\"\"You are a question rewriter, rewrite the question from the user in an optimized way without changin its semantic meaning for web search\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system),\n",
    "        (\"human\",\"Here is the initial user question : {question} formualte in a better optimized way \")\n",
    "    ]\n",
    ")\n",
    "rewriter = prompt|llm|output_parser\n",
    "# print(rewriter.invoke(\"What is the name shake value\"))\n",
    "\n",
    "#4.Websearch tool\n",
    "google_search = TavilySearchResults()\n",
    "def tavily_tool(question):\n",
    "    result = google_search.invoke({\"query\":question})\n",
    "    return result\n",
    "\n",
    "#Create Pydantic\n",
    "class DocMetadata(BaseModel):\n",
    "    document_name: str\n",
    "    page_num: int\n",
    "    heading: Optional[str]\n",
    "    sub_heading: Optional[str]\n",
    "    sub_sub_heading: Optional[str]\n",
    "    snippet: Optional[List[str]] = []\n",
    "\n",
    "class SerializableDoc(BaseModel):\n",
    "    page_content: str\n",
    "    metadata: dict\n",
    "    \n",
    "\n",
    "class Agent_type(TypedDict):\n",
    "    question: str\n",
    "    generation: str | None\n",
    "    web_search: str\n",
    "    documents: List[dict]\n",
    "\n",
    "def serialize_docs(docs: list[LCDocument]) -> list[SerializableDoc]:\n",
    "    return [\n",
    "        {\n",
    "            \"page_content\": d.page_content,\n",
    "            \"metadata\": make_msgpack_safe(d.metadata)\n",
    "        }\n",
    "        for d in docs\n",
    "    ]\n",
    "\n",
    "#1.Retriever node\n",
    "def retriever_node(state: Agent_type):\n",
    "    print(\"____Retriever____\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    history = format_chat_history()\n",
    "\n",
    "    enriched_query = f\"\"\"\n",
    "Conversation Context:\n",
    "{history}\n",
    "\n",
    "Current Question:\n",
    "{question}\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        docs = retriever.invoke(enriched_query)\n",
    "        documents = serialize_docs(docs)\n",
    "    except Exception as e:\n",
    "        print(\"Retriever failed:\", e)\n",
    "        documents = []\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"web_search\": \"no\",\n",
    "        \"generation\": None\n",
    "    }\n",
    "\n",
    "# retrieved_state = retriever_node({\"question\":\"What is negation\"})\n",
    "# print(retrieved_state)\n",
    "\n",
    "#2. Generate node\n",
    "def generate_node(state: Agent_type):\n",
    "    print(\"____Generate____\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    if state[\"web_search\"] == \"yes\":\n",
    "        generation = web_chain.invoke(state)\n",
    "    else:\n",
    "        generation = rag_chain.invoke(state)\n",
    "\n",
    "    #Save conversation\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": generation}\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"generation\": generation,\n",
    "        \"web_search\": state[\"web_search\"]\n",
    "    }\n",
    "\n",
    "#3. Grade_node\n",
    "def grade_node(state: Agent_type):\n",
    "    print(\"____Grader____\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    filtered_docs = []\n",
    "    web_search = \"no\"\n",
    "\n",
    "    for doc in documents:\n",
    "        content = doc[\"page_content\"]\n",
    "\n",
    "        if not content.strip():\n",
    "            web_search = \"yes\"\n",
    "            continue\n",
    "\n",
    "        score = grader.invoke({\n",
    "            \"question\": question,\n",
    "            \"documents\": content,\n",
    "            \"chat_history\": format_chat_history()\n",
    "        })\n",
    "\n",
    "        if score.binary_score == \"Yes\":\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            web_search = \"yes\"\n",
    "\n",
    "    if not filtered_docs:\n",
    "        web_search = \"yes\"\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": filtered_docs,\n",
    "        \"web_search\": web_search\n",
    "    }\n",
    "\n",
    "\n",
    "#4. Rewriter Node\n",
    "def rewriter_node(state:Agent_type):\n",
    "    question = state['question']\n",
    "    rewrited_query = rewriter.invoke({\"question\":question})\n",
    "    return {\"question\":rewrited_query,\"documents\": state[\"documents\"],\n",
    "        \"web_search\": state[\"web_search\"]}\n",
    "\n",
    "#5. Web search\n",
    "def web_search_node(state: Agent_type):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    results = tavily_tool(question)\n",
    "    web_text = \"\\n\".join(\n",
    "        r[\"content\"] if isinstance(r, dict) else str(r)\n",
    "        for r in results\n",
    "    )\n",
    "\n",
    "    documents.append({\n",
    "        \"page_content\": web_text,\n",
    "        \"metadata\": {\"source\": \"web\"}\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents\n",
    "    }\n",
    "\n",
    "\n",
    "#6. Decision Maker\n",
    "def decision_to_generate_node(state:Agent_type):\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    web_search = state['web_search']\n",
    "\n",
    "    if web_search == \"yes\":\n",
    "        print(\"Question will be transformed by rewriting the query in a way that web search can able to understand\")\n",
    "        return \"rewriter_node\"\n",
    "    \n",
    "    else:\n",
    "        return \"generate_node\"\n",
    "\n",
    "workflow = StateGraph(Agent_type)\n",
    "workflow.add_node(\"Retriever\",retriever_node)\n",
    "workflow.add_node(\"Generation\",generate_node)\n",
    "workflow.add_node(\"Web search\",web_search_node)\n",
    "workflow.add_node(\"Rewriter\",rewriter_node)\n",
    "workflow.add_node(\"Grader\",grade_node)\n",
    "workflow.set_entry_point(\"Retriever\")\n",
    "workflow.add_edge(\"Retriever\",\"Grader\")\n",
    "workflow.add_conditional_edges(\"Grader\",decision_to_generate_node,{\"rewriter_node\":\"Rewriter\",\"generate_node\":\"Generation\"})\n",
    "workflow.add_edge(\"Rewriter\",\"Web search\")\n",
    "workflow.add_edge(\"Web search\",\"Generation\")\n",
    "workflow.add_edge(\"Generation\",END)\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "config = {\"configurable\":{\"thread_id\":1}}\n",
    "\n",
    "answer = app.invoke({\"question\":\"What is the use of tavily search\"},config,stream_mode=\"values\")\n",
    "print(answer['generation'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc2a329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b505005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph\n",
      "Version: 1.0.3\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: https://docs.langchain.com/oss/python/langgraph/overview\n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
      "Required-by: langchain\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51968186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c914bc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81bb612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca341c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19ff06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9edbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05cf54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4d068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
